{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import vk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваем с хтмл страницы первую тысячу человек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем у них ссылки и ФИО\n",
    "\n",
    "После отбираем уникальные фамилии и имена, чтобы искать больше людей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веб-скрапим страницы и получаем ссылки и имена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labeled name.html', 'r') as f:\n",
    "\n",
    "    contents = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(contents, 'html.parser')\n",
    "\n",
    "#     print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['link', 'id', 'name', 'last_name', 'city', 'education', 'interests', 'music', 'movies', 'tv', 'books', 'games', 'can_see_audio'])\n",
    "\n",
    "info = soup.find_all('div', class_ = 'people_row search_row clear_fix')\n",
    "\n",
    "for item in info:\n",
    "    div = item.find_all('div', class_ = 'labeled name')\n",
    "    a_class = div[0].find_all('a')\n",
    "#     print(i)\n",
    "#     print(type(a_class[0]))\n",
    "    link = a_class[0].get('href')\n",
    "    spl = a_class[0].text.split(' ')\n",
    "    name = spl[0]\n",
    "    last_name = spl[1]\n",
    "#     name = str(a_class[0].find_all('img')[0]).split(\"\\\"\")[1]\n",
    "    \n",
    "    test = item.find_all('div', class_ = 'labeled')\n",
    "    if (len(test) > 1):\n",
    "        if ('Россия' in test[1].text):\n",
    "            city = test[1].text\n",
    "        else:\n",
    "            city = None\n",
    "    else:\n",
    "        city = None\n",
    "    df = df.append({'link': link, 'name': name, 'last_name': last_name, 'city': city}, ignore_index=True)\n",
    "    \n",
    "df.to_excel('init_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n",
      "870\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(np.unique(df['name'])))\n",
    "\n",
    "print(len(np.unique(df['last_name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'name': np.unique(df['name'])}\n",
    "f = {'name': np.unique(df['last_name'])}\n",
    "unique_names = pd.DataFrame(data = d)\n",
    "unique_lasts = pd.DataFrame(data = f)\n",
    "# unique_names = unique_names.append(np.unique(df['last_name']))\n",
    "unique_values = pd.concat([unique_names, unique_lasts], ignore_index=True)\n",
    "unique_values.to_excel('unique_names.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
